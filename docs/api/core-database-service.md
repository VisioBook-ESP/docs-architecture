# API Documentation - Core Database Service

## Vue d'ensemble du service

### R√¥le et responsabilit√©s
Le **Core Database Service** est le service fondamental qui g√®re toutes les connexions et op√©rations de base de donn√©es pour l'ensemble de l'√©cosyst√®me Visiobook. Il centralise la gestion des pools de connexions, les transactions distribu√©es, et assure la coh√©rence des donn√©es.

### Justification de l'atomisation
- **Point unique de d√©faillance contr√¥l√©** : Centralise la logique de base de donn√©es
- **Optimisation des performances** : Pool de connexions optimis√© et cache intelligent
- **S√©curit√©** : Gestion centralis√©e des acc√®s et chiffrement
- **Maintenance** : Migrations et sauvegardes centralis√©es

### Informations techniques
- **Port** : 8084
- **Technology Stack** : NestJS + TypeScript + Prisma
- **Databases** : PostgreSQL, Redis
- **Version API** : v1

## Architecture du service

```mermaid
graph TB
    subgraph "Core Database Service"
        API[API Layer<br/>NestJS + TypeScript]
        POOL[Connection Pool Manager<br/>Prisma + ioredis]
        CACHE[Cache Layer<br/>Redis Cluster]
        MIGRATE[Migration Manager<br/>Prisma Migrate]
        BACKUP[Backup Manager<br/>Automated Backups]
        GUARD[Auth Guard<br/>JWT Validation]
    end

    subgraph "Databases"
        PG[(PostgreSQL<br/>Primary Data)]
        REDIS[(Redis<br/>Cache + Sessions)]
    end

    API --> GUARD
    API --> POOL
    POOL --> PG
    POOL --> REDIS
    API --> CACHE
    API --> MIGRATE
    API --> BACKUP

    classDef service fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef database fill:#fff8e1,stroke:#f9a825,stroke-width:2px

    class API,POOL,CACHE,MIGRATE,BACKUP,GUARD service
    class PG,REDIS database
```

### Architecture de Donn√©es - Strat√©gie de Migration

#### Note sur l'approche architecturale actuelle

> **üèóÔ∏è Phase de d√©veloppement d√©centralis√© (Actuelle)**
>
> Pour faciliter le d√©veloppement parall√®le des microservices, chaque service g√®re actuellement ses propres tables pour les objets dont il est responsable. Les objets provenant d'autres services sont "mock√©s" localement dans chaque base de donn√©es.
>
> **üéØ Phase de centralisation future (Roadmap)**
>
> Le Core Database Service r√©cup√©rera progressivement les fichiers de migration de tous les microservices et centralisera l'acc√®s aux donn√©es via des contrats d'interface standardis√©s.

#### Sch√©mas de R√©f√©rence Centralis√©s (Future)

Les sch√©mas ci-dessous repr√©sentent la structure de donn√©es unifi√©e qui sera mise en place lors de la centralisation :

```sql
-- Unified Users table (source: Core User Service)
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    username VARCHAR(100) UNIQUE,
    password_hash VARCHAR(255) NOT NULL,
    first_name VARCHAR(100),
    last_name VARCHAR(100),
    role VARCHAR(50) DEFAULT 'user',
    subscription_type VARCHAR(50) DEFAULT 'free',
    email_verified BOOLEAN DEFAULT FALSE,
    phone_verified BOOLEAN DEFAULT FALSE,
    mfa_enabled BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    deleted_at TIMESTAMP
);

-- Unified Projects table (source: Core Project Service)
CREATE TABLE projects (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    status VARCHAR(50) DEFAULT 'draft',
    visibility VARCHAR(50) DEFAULT 'private',
    source_content_id UUID,
    generated_content_id UUID,
    settings JSONB DEFAULT '{}',
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    deleted_at TIMESTAMP
);

-- Unified Files table (source: Support Storage Service)
CREATE TABLE files (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    project_id UUID REFERENCES projects(id),
    original_name VARCHAR(255) NOT NULL,
    file_path VARCHAR(500) NOT NULL,
    file_type VARCHAR(100) NOT NULL,
    mime_type VARCHAR(100) NOT NULL,
    size_bytes BIGINT NOT NULL,
    checksum_md5 VARCHAR(32) NOT NULL,
    storage_provider VARCHAR(50) DEFAULT 'azure_blob',
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Unified Analysis Jobs table (source: AI Analysis Service)
CREATE TABLE analysis_jobs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    project_id UUID REFERENCES projects(id),
    job_type VARCHAR(100) NOT NULL,
    status VARCHAR(50) DEFAULT 'pending',
    parameters JSONB NOT NULL,
    result JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    completed_at TIMESTAMP
);
```

#### Strat√©gie de Migration des Microservices

##### Phase 1 - Collecte des Migrations (En cours)
1. **R√©cup√©ration automatique** des fichiers de migration de chaque service
2. **Analyse des sch√©mas** pour identifier les d√©pendances et conflits
3. **Mapping des objets** entre services (utilisateurs, projets, fichiers, etc.)
4. **Validation des contrats** d'interface propos√©s

##### Phase 2 - Impl√©mentation des Contrats (Future)
1. **D√©ploiement des contrats** d'interface standardis√©s
2. **Migration progressive** service par service
3. **Tests de compatibilit√©** et validation des donn√©es
4. **Monitoring** des performances et de la fiabilit√©

##### Phase 3 - Centralisation Compl√®te (Future)
1. **D√©commissionnement** des bases de donn√©es locales
2. **Optimisation** des requ√™tes centralis√©es
3. **Mise en place** de la haute disponibilit√©
4. **Documentation** finale et formation des √©quipes

#### Processus de R√©cup√©ration des Migrations

```bash
# Script de collecte automatique des migrations
#!/bin/bash

# Collecte depuis chaque microservice
collect_migrations() {
    services=("core-user-service" "core-project-service" "support-storage-service" "ai-analysis-service")

    for service in "${services[@]}"; do
        echo "Collecting migrations from $service..."

        # R√©cup√©ration des fichiers de migration
        rsync -av $service/migrations/ ./collected-migrations/$service/

        # Analyse des d√©pendances
        python analyze_dependencies.py ./collected-migrations/$service/

        # G√©n√©ration des contrats d'interface
        python generate_contracts.py $service
    done
}

# Validation des contrats
validate_contracts() {
    echo "Validating interface contracts..."
    python validate_contracts.py ./contracts/
}

# G√©n√©ration du sch√©ma unifi√©
generate_unified_schema() {
    echo "Generating unified database schema..."
    python merge_schemas.py ./collected-migrations/ > unified_schema.sql
}
```

### Variables d'environnement

```bash
# Database connections
DATABASE_URL=postgresql://user:password@localhost:5432/visiobook
REDIS_URL=redis://localhost:6379

# Connection pools
DB_POOL_MIN=5
DB_POOL_MAX=20
DB_POOL_IDLE_TIMEOUT=30000
REDIS_POOL_SIZE=10

# NestJS Configuration
NODE_ENV=production
PORT=8084

# Security
DB_ENCRYPTION_KEY=your-encryption-key
JWT_SECRET=your-jwt-secret

# Monitoring
PROMETHEUS_PORT=9090
LOG_LEVEL=info

# Prisma
PRISMA_SCHEMA_DISABLE_ADVISORY_LOCK=1
```

## Authentification et s√©curit√©

> **üìã R√©f√©rence** : Voir [R√®gles Communes](./regles_communes.md) pour les standards d'authentification, permissions et s√©curit√©.

### Syst√®me JWT
```json
{
  "Authorization": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "Content-Type": "application/json"
}
```

### Structure du JWT Token
```json
{
  "sub": "user_uuid",
  "email": "user@example.com",
  "role": "user|premium|admin",
  "subscription_type": "free|premium",
  "permissions": ["domain:action:resource"],
  "iat": 1642234567,
  "exp": 1642320967,
  "jti": "token_unique_id"
}
```

### Niveaux de permissions
- **admin** : Acc√®s complet aux op√©rations de maintenance et monitoring
- **user** : Acc√®s aux op√©rations CRUD sur ses propres donn√©es
- **premium** : Acc√®s √©tendu avec quotas augment√©s

### Headers de s√©curit√© requis
```http
Authorization: Bearer <jwt_token>
X-Request-ID: <unique_request_id>
X-Client-Version: <client_version>
```

## Endpoints API

### Health & Monitoring

#### GET /health
**Description** : V√©rification de l'√©tat du service et des connexions DB

**Permissions** : Aucune

**R√©ponse** :
```json
{
  "status": "UP",
  "timestamp": "2024-01-15T10:30:00Z",
  "service": "core-database-service",
  "version": "1.0.0",
  "checks": {
    "postgresql": {
      "status": "UP",
      "responseTime": "15ms",
      "connections": {
        "active": 8,
        "idle": 12,
        "total": 20
      }
    },
    "redis": {
      "status": "UP",
      "responseTime": "2ms",
      "memory": "45MB"
    },
    "prisma": {
      "status": "UP",
      "responseTime": "8ms",
      "migrations": "up_to_date"
    }
  }
}
```

#### GET /metrics
**Description** : M√©triques Prometheus

**Permissions** : admin

### Connection Management

#### POST /api/v1/connections/acquire
**Description** : Acquisition d'une connexion DB pour un service

**Permissions** : user, premium, admin

**Requ√™te** :
```json
{
  "service_name": "core-user-service",
  "database_type": "postgresql",
  "operation_type": "read" // ou "write"
}
```

**R√©ponse** :
```json
{
  "connection_id": "conn_123456789",
  "database_url": "postgresql://...",
  "expires_at": "2024-01-15T10:35:00Z",
  "pool_stats": {
    "active": 9,
    "idle": 11,
    "waiting": 0
  }
}
```

#### POST /api/v1/connections/release
**Description** : Lib√©ration d'une connexion DB

**Permissions** : user, premium, admin

**Requ√™te** :
```json
{
  "connection_id": "conn_123456789",
  "service_name": "core-user-service"
}
```

**R√©ponse** :
```json
{
  "status": "released",
  "connection_id": "conn_123456789",
  "duration_ms": 1250
}
```

### Data Operations

#### POST /api/v1/data/query
**Description** : Ex√©cution de requ√™tes s√©curis√©es

**Permissions** : user, premium, admin

**Requ√™te** :
```json
{
  "database": "postgresql",
  "query_type": "select",
  "table": "projects",
  "filters": {
    "user_id": "uuid",
    "status": "active"
  },
  "pagination": {
    "page": 1,
    "limit": 20
  }
}
```

**R√©ponse** :
```json
{
  "data": [
    {
      "id": "proj_123",
      "title": "Mon projet",
      "status": "active",
      "created_at": "2024-01-15T10:00:00Z"
    }
  ],
  "pagination": {
    "page": 1,
    "limit": 20,
    "total": 45,
    "pages": 3
  },
  "execution_time_ms": 25
}
```

#### POST /api/v1/data/transaction
**Description** : Ex√©cution de transactions distribu√©es

**Permissions** : user, premium, admin

**Requ√™te** :
```json
{
  "operations": [
    {
      "database": "postgresql",
      "operation": "insert",
      "table": "projects",
      "data": {
        "title": "Nouveau projet",
        "user_id": "user_123"
      }
    },
    {
      "database": "redis",
      "operation": "set",
      "key": "project:cache:proj_new",
      "value": "{\"status\": \"created\"}",
      "ttl": 3600
    }
  ]
}
```

**R√©ponse** :
```json
{
  "transaction_id": "tx_789456123",
  "status": "committed",
  "results": [
    {
      "operation": 1,
      "status": "success",
      "data": {
        "id": "proj_new_123",
        "created_at": "2024-01-15T10:30:00Z"
      }
    },
    {
      "operation": 2,
      "status": "success"
    }
  ],
  "execution_time_ms": 45
}
```

### Migration Management

#### GET /api/v1/migrations/status
**Description** : √âtat des migrations de base de donn√©es

**Permissions** : admin

**R√©ponse** :
```json
{
  "current_version": "20240115_001",
  "pending_migrations": [
    {
      "version": "20240116_001",
      "description": "Add indexes for performance",
      "estimated_duration": "2 minutes"
    }
  ],
  "last_migration": {
    "version": "20240115_001",
    "applied_at": "2024-01-15T09:00:00Z",
    "duration_ms": 1500
  }
}
```

#### POST /api/v1/migrations/run
**Description** : Ex√©cution des migrations en attente

**Permissions** : admin

**Requ√™te** :
```json
{
  "target_version": "20240116_001", // optionnel
  "dry_run": false
}
```

**R√©ponse** :
```json
{
  "migration_id": "mig_123456",
  "status": "running",
  "progress": {
    "current_step": 1,
    "total_steps": 3,
    "estimated_remaining": "1 minute"
  }
}
```

## Flux de transactions CRUD

### Diagramme de s√©quence - Op√©ration de lecture

```mermaid
sequenceDiagram
    participant Client as Service Client
    participant API as Database API
    participant Pool as Connection Pool
    participant Cache as Redis Cache
    participant DB as PostgreSQL

    Client->>API: POST /api/v1/data/query
    API->>Cache: Check cache for query
    alt Cache Hit
        Cache-->>API: Return cached data
        API-->>Client: Return data (cached)
    else Cache Miss
        API->>Pool: Acquire connection
        Pool->>DB: Get connection
        DB-->>Pool: Connection ready
        Pool-->>API: Connection acquired
        API->>DB: Execute query
        DB-->>API: Query results
        API->>Cache: Store in cache (TTL: 300s)
        API->>Pool: Release connection
        API-->>Client: Return data
    end
```

### Diagramme de flux - Transaction distribu√©e

```mermaid
flowchart TD
    Start([Transaction Request]) --> Validate{Validate Operations}
    Validate -->|Invalid| Error[Return Error 400]
    Validate -->|Valid| Begin[Begin Transaction]

    Begin --> AcquireConn[Acquire Connections]
    AcquireConn --> CheckConn{All Connections OK?}
    CheckConn -->|No| ReleaseConn[Release Connections]
    ReleaseConn --> Error503[Return Error 503]

    CheckConn -->|Yes| ExecuteOps[Execute Operations]
    ExecuteOps --> CheckResults{All Operations Success?}

    CheckResults -->|No| Rollback[Rollback Transaction]
    Rollback --> ReleaseConn

    CheckResults -->|Yes| Commit[Commit Transaction]
    Commit --> UpdateCache[Update Cache]
    UpdateCache --> ReleaseConn2[Release Connections]
    ReleaseConn2 --> Success[Return Success 200]

    Error --> End([End])
    Error503 --> End
    Success --> End
```

## Parcours utilisateurs d√©taill√©s

### Milestone 1: Importer un contenu

**US 1.1 - Import de fichiers**
```
1. POST /api/v1/data/transaction
   - Insert project record
   - Store file metadata
   - Update user project count

2. POST /api/v1/connections/acquire (for ai-analysis-service)
   - Acquire connection for content analysis
```

**US 1.5 - Extraction des sc√®nes cl√©s**
```
1. POST /api/v1/data/query
   - Retrieve project content
   - Get analysis parameters

2. POST /api/v1/data/transaction
   - Store scene analysis results
   - Update project status
```

### Milestone 3: G√©n√©rer et visualiser une animation

**US 3.1 - G√©n√©ration automatique**
```
1. POST /api/v1/data/query
   - Get project data and analysis
   - Retrieve user preferences

2. POST /api/v1/data/transaction
   - Create generation job record
   - Update project status to "generating"
```

### Milestone 5: Historique et r√©utilisation

**US 5.1 - Acc√©der √† l'historique**
```
1. POST /api/v1/data/query
   - Query user projects with pagination
   - Include project metadata and status
```

**US 5.2 - Modifier un projet existant**
```
1. POST /api/v1/data/transaction
   - Create project version backup
   - Update project with new parameters
   - Invalidate related cache entries
```

## Codes d'erreur

| Code | Message | Description |
|------|---------|-------------|
| 200 | Success | Op√©ration r√©ussie |
| 400 | Bad Request | Requ√™te malform√©e ou param√®tres invalides |
| 401 | Unauthorized | Token JWT manquant ou invalide |
| 403 | Forbidden | Permissions insuffisantes |
| 404 | Not Found | Ressource non trouv√©e |
| 409 | Conflict | Conflit de donn√©es (ex: email d√©j√† utilis√©) |
| 429 | Too Many Requests | Limite de taux d√©pass√©e |
| 500 | Internal Server Error | Erreur interne du serveur |
| 503 | Service Unavailable | Base de donn√©es indisponible |
| 504 | Gateway Timeout | Timeout de connexion √† la base de donn√©es |

### Format d'erreur standardis√©
```json
{
  "error": {
    "code": "VISIOBOOK_SERVICE_UNAVAILABLE",
    "message": "Unable to acquire database connection",
    "details": {
      "database": "postgresql",
      "pool_status": "exhausted",
      "retry_after": 30
    },
    "timestamp": "2024-01-15T10:30:00Z",
    "request_id": "req_123456789",
    "service": "core-database-service"
  }
}
```

## Contrats d'Interface

### Vue d'ensemble
Le Core Database Service pr√©pare la centralisation progressive des donn√©es des microservices. Les contrats d'interface suivants d√©finissent les APIs futures qui permettront aux autres services de migrer vers une architecture centralis√©e.

### Interface User Contract
```typescript
interface UserContract {
  // Donn√©es de base
  getUserById(id: string): Promise<User>;
  getUserByEmail(email: string): Promise<User>;
  createUser(userData: CreateUserData): Promise<User>;
  updateUser(id: string, userData: UpdateUserData): Promise<User>;
  deleteUser(id: string): Promise<boolean>;

  // Authentification
  validateCredentials(email: string, password: string): Promise<AuthResult>;
  createSession(userId: string, deviceInfo: DeviceInfo): Promise<Session>;
  validateSession(sessionToken: string): Promise<Session>;
  refreshSession(refreshToken: string): Promise<Session>;

  // Permissions et r√¥les
  getUserPermissions(userId: string): Promise<Permission[]>;
  hasPermission(userId: string, permission: string): Promise<boolean>;
  updateUserRole(userId: string, role: string): Promise<boolean>;

  // Profils utilisateur
  getUserProfile(userId: string): Promise<UserProfile>;
  updateUserProfile(userId: string, profileData: UpdateProfileData): Promise<UserProfile>;
}

interface User {
  id: string;
  email: string;
  username?: string;
  first_name?: string;
  last_name?: string;
  role: 'user' | 'premium' | 'admin';
  subscription_type: 'free' | 'premium';
  email_verified: boolean;
  phone_verified: boolean;
  mfa_enabled: boolean;
  created_at: string;
  updated_at: string;
}
```

### Interface Project Contract
```typescript
interface ProjectContract {
  // CRUD de base
  getProjectById(id: string): Promise<Project>;
  getProjectsByUser(userId: string, filters?: ProjectFilters): Promise<Project[]>;
  createProject(projectData: CreateProjectData): Promise<Project>;
  updateProject(id: string, projectData: UpdateProjectData): Promise<Project>;
  deleteProject(id: string): Promise<boolean>;

  // Versioning
  getProjectVersions(projectId: string): Promise<ProjectVersion[]>;
  createProjectVersion(projectId: string, versionData: VersionData): Promise<ProjectVersion>;
  restoreProjectVersion(projectId: string, versionNumber: number): Promise<boolean>;

  // Workflows
  getProjectWorkflows(projectId: string): Promise<Workflow[]>;
  createWorkflow(projectId: string, workflowData: WorkflowData): Promise<Workflow>;
  updateWorkflowStatus(workflowId: string, status: string): Promise<boolean>;
}

interface Project {
  id: string;
  user_id: string;
  title: string;
  description?: string;
  status: 'draft' | 'active' | 'completed' | 'archived';
  visibility: 'private' | 'shared' | 'public';
  settings: ProjectSettings;
  metadata: ProjectMetadata;
  created_at: string;
  updated_at: string;
}
```

### Interface Storage Contract
```typescript
interface StorageContract {
  // Gestion des fichiers
  getFileById(id: string): Promise<FileMetadata>;
  getFilesByProject(projectId: string): Promise<FileMetadata[]>;
  getFilesByUser(userId: string, filters?: FileFilters): Promise<FileMetadata[]>;
  createFileRecord(fileData: CreateFileData): Promise<FileMetadata>;
  updateFileMetadata(id: string, metadata: UpdateFileData): Promise<FileMetadata>;
  deleteFile(id: string): Promise<boolean>;

  // Transformations
  getFileTransformations(fileId: string): Promise<Transformation[]>;
  createTransformation(transformData: CreateTransformData): Promise<Transformation>;
  getTransformationStatus(transformId: string): Promise<TransformationStatus>;
  updateTransformationProgress(transformId: string, progress: number): Promise<boolean>;

  // CDN et cache
  getCDNUrls(fileId: string): Promise<CDNUrls>;
  invalidateCDNCache(fileIds: string[]): Promise<boolean>;
  getStorageStats(userId: string): Promise<StorageStats>;
}

interface FileMetadata {
  id: string;
  user_id: string;
  project_id?: string;
  original_name: string;
  file_path: string;
  file_type: string;
  mime_type: string;
  size_bytes: number;
  checksum_md5: string;
  storage_provider: string;
  is_public: boolean;
  metadata: Record<string, any>;
  created_at: string;
  updated_at: string;
}
```

### Interface AI Contract
```typescript
interface AIContract {
  // Analyses
  getAnalysisJobs(projectId: string): Promise<AnalysisJob[]>;
  createAnalysisJob(jobData: CreateAnalysisData): Promise<AnalysisJob>;
  getJobStatus(jobId: string): Promise<JobStatus>;
  updateJobProgress(jobId: string, progress: number): Promise<boolean>;
  getAnalysisResults(jobId: string): Promise<AnalysisResult>;

  // G√©n√©rations
  getGenerationJobs(projectId: string): Promise<GenerationJob[]>;
  createGenerationJob(jobData: CreateGenerationData): Promise<GenerationJob>;
  getGenerationStatus(jobId: string): Promise<GenerationStatus>;
  getGenerationResults(jobId: string): Promise<GenerationResult>;

  // Mod√®les et performance
  getAvailableModels(): Promise<AIModel[]>;
  getModelPerformance(modelName: string): Promise<ModelPerformance>;
  updateModelMetrics(modelName: string, metrics: ModelMetrics): Promise<boolean>;
}

interface AnalysisJob {
  id: string;
  project_id: string;
  job_type: string;
  status: 'pending' | 'running' | 'completed' | 'failed';
  progress_percent: number;
  parameters: Record<string, any>;
  result?: AnalysisResult;
  error_message?: string;
  created_at: string;
  started_at?: string;
  completed_at?: string;
}
```

### Strat√©gie de Migration des Contrats

#### Phase 1 - Impl√©mentation des contrats (En cours)
- D√©veloppement des interfaces TypeScript
- Impl√©mentation des endpoints correspondants
- Tests avec donn√©es mock√©es
- Documentation des contrats

#### Phase 2 - Migration progressive (Future)
- Migration service par service vers les contrats
- Maintien de la compatibilit√© avec les APIs existantes
- Monitoring des performances et de la fiabilit√©
- Formation des √©quipes de d√©veloppement

#### Phase 3 - Consolidation (Future)
- D√©commissionnement des connexions directes
- Optimisation des performances centralis√©es
- Mise en place de la haute disponibilit√©
- Documentation finale et formation

### Endpoints de Contrats (Futurs)

#### GET /api/v1/contracts/user/{user_id}
**Description** : Acc√®s aux donn√©es utilisateur via contrat centralis√©

**Permissions** : user, premium, admin

**R√©ponse** :
```json
{
  "user": {
    "id": "user_123456789",
    "email": "user@example.com",
    "role": "premium",
    "subscription_type": "premium",
    "profile": {
      "first_name": "John",
      "last_name": "Doe",
      "avatar_url": "https://cdn.visiobook.com/avatars/user_123.jpg"
    }
  },
  "source": "centralized_contract",
  "cache_status": "hit",
  "response_time_ms": 15
}
```

#### GET /api/v1/contracts/project/{project_id}
**Description** : Acc√®s aux donn√©es projet via contrat centralis√©

**Permissions** : user, premium, admin

**R√©ponse** :
```json
{
  "project": {
    "id": "proj_123456789",
    "title": "Mon Projet",
    "status": "active",
    "workflows": [
      {
        "id": "workflow_456789",
        "type": "ai_analysis",
        "status": "completed"
      }
    ]
  },
  "source": "centralized_contract",
  "aggregated_from": ["project_service", "user_service", "ai_service"]
}
```

## Versioning et migration

### Convention v1
- **URL Base** : `/api/v1/`
- **Headers** : `Accept: application/vnd.visiobook.v1+json`
- **R√©trocompatibilit√©** : Maintenue pendant 12 mois minimum

### Strat√©gie de migration
1. **D√©pr√©ciation** : Annonce 6 mois avant suppression
2. **Coexistence** : v1 et v2 fonctionnent en parall√®le
3. **Migration automatique** : Scripts de migration des donn√©es
4. **Documentation** : Guide de migration d√©taill√©

### Exemple de migration v1 ‚Üí v2
```json
{
  "migration": {
    "from_version": "v1",
    "to_version": "v2",
    "changes": [
      {
        "type": "endpoint_renamed",
        "old": "/api/v1/data/query",
        "new": "/api/v2/data/search"
      },
      {
        "type": "field_added",
        "endpoint": "/api/v2/data/search",
        "field": "search_options"
      }
    ],
    "breaking_changes": false,
    "migration_deadline": "2024-12-31"
  }
}
